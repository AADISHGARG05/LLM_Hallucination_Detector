# LLM_Hallucination_Detector
Multi-Signal Hallucination Detection System for LLM-Generated Text An explainable ML system that detects hallucination risk in AI-generated text using a BERT classifier, semantic consistency analysis, and linguistic uncertainty signals, deployed with Flask and a modern web UI.
